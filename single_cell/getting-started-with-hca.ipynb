{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Getting Started with the Human Cell Atlas\n",
    "\n",
    "## Overview\n",
    "\n",
    "[Human Cell Atlas (HCA)](https://humancellatlas.org) data is organized into \"Projects\" which can be discovered through the Catalog. You can interactively [browse the Catalog](https://data.humancellatlas.org/explore/projects) or access it via the public [Data Browser API](https://data.humancellatlas.org/apis/api-documentation/data-browser-api).\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "\n",
    "- access the Catalog\n",
    "- access metadata for a Project\n",
    "- download the data for a Project\n",
    "\n",
    "Examples illustrated in this notebook are based on [examples](https://github.com/verily-src/azul/blob/prod/docs/) in the [Azul](https://github.com/verily-src/azul) repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup\n",
    "\n",
    "Run the cell below to set up libraries and utilities for this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the standard \"requests\" library for programmatic access of HTTP URLs\n",
    "import requests\n",
    "\n",
    "# Import the standard \"os\" module for URL path manipulation\n",
    "import os\n",
    "\n",
    "# Import \"tqdm\" to display a progress bar during downloads\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Set notebook globals\n",
    "\n",
    "The notebook needs to know:\n",
    "    \n",
    "- URL endpoint for the HCA catalog\n",
    "- Where to save downloaded files\n",
    "- An example project's UUID to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CATALOG_PREFIX = 'dcp'\n",
    "ENDPOINT_URL = f'https://service.azul.data.humancellatlas.org/index'\n",
    "CATALOGS_URL = f'{ENDPOINT_URL}/catalogs'\n",
    "PROJECTS_URL = f'{ENDPOINT_URL}/projects'\n",
    "\n",
    "HCA_EXAMPLES_DIR = os.path.expanduser('~/wb-tutorials/hca')\n",
    "OUTPUT_DIR = os.path.join(HCA_EXAMPLES_DIR, 'data')\n",
    "\n",
    "!mkdir -p \"{OUTPUT_DIR}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create utility routines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### fetch_json\n",
    "\n",
    "Fetch a URL, handle errors, and return the response json on success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fetch_json(url: str, params: dict) -> list:\n",
    "    response = requests.get(url, params=params)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### list_catalogs\n",
    "\n",
    "Returns a list of catalogs from the server.\n",
    "\n",
    "The list of catalogs is expected to look something like:\n",
    "\n",
    "  * ['dcp31', 'dcp32', 'dcp1', 'lm2', 'lm3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def list_catalogs() -> list:\n",
    "    response = fetch_json(CATALOGS_URL, None)\n",
    "\n",
    "    catalogs = []\n",
    "    for catalog, details in response['catalogs'].items():\n",
    "        if not details['internal']:\n",
    "            catalogs.append(catalog)\n",
    "\n",
    "    return catalogs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### get_dcp_catalog\n",
    "\n",
    "The Data Coordination Platform (DCP) publishes new catalogs periodically.\n",
    "Extract the \"latest\" DCP catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dcp_catalog() -> str:\n",
    "    # We want to latest dcp catalog.\n",
    "    catalogs = list_catalogs()\n",
    "    \n",
    "    # Extract the 'dcp' catalogs\n",
    "    dcp_catalogs = [c for c in catalogs if c.startswith(CATALOG_PREFIX)]\n",
    "    \n",
    "    # Get the largest numerically\n",
    "    max_value = 0\n",
    "    max_catalog = None\n",
    "    for c in dcp_catalogs:\n",
    "        if int(c[len(CATALOG_PREFIX):]) > max_value:\n",
    "            max_value = int(c[len(CATALOG_PREFIX):])\n",
    "            max_catalog = c\n",
    "    \n",
    "    return max_catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### download_file \n",
    "\n",
    "Downloads the content of the specified URL to a local output path,\n",
    "while displaying a progress bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_file(url: str, output_path: str) -> None:\n",
    "    # Start the request stream\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    # Get the content length so the progress bar can display accurate progress\n",
    "    total = int(response.headers.get('content-length', 0))\n",
    "    print(f'Downloading to: {output_path}', flush=True)\n",
    "    \n",
    "    # Fetch the content in chunks, updating the progress bar\n",
    "    with open(output_path, 'wb') as f:\n",
    "        with tqdm(total=total, unit='B', unit_scale=True, unit_divisor=1024) as bar:\n",
    "            for chunk in response.iter_content(chunk_size=1024):\n",
    "                size = f.write(chunk)\n",
    "                bar.update(size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "#### get_project_request_params\n",
    "\n",
    "Get params to fetch the list of projects in the HCA catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_project_request_params(catalog: str, max_projects: int) -> dict:\n",
    "\n",
    "    # Set up request parameters\n",
    "    return {\n",
    "      'catalog': catalog,\n",
    "      'size': max_projects,\n",
    "      'sort': 'projectTitle',\n",
    "      'order': 'asc'\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### list_projects \n",
    "\n",
    "Fetch the list of projects in the HCA catalog.\n",
    "Return a list of project titles and UUIDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def list_projects(catalog: str, max_projects: int) -> list:\n",
    "\n",
    "    # Allocate a list to populate for return\n",
    "    project_list = []\n",
    "\n",
    "    print(f\"Fetching first {max_projects} projects:\")\n",
    "    \n",
    "    # Set up the fetch parameters\n",
    "    url = PROJECTS_URL\n",
    "    params = get_project_request_params(catalog, max_projects)\n",
    "    \n",
    "    while url and len(project_list) < max_projects:\n",
    "        response_json = fetch_json(url, params)\n",
    "\n",
    "        # Iterate over results, pulling out key project elements\n",
    "        for hit in response_json['hits']:\n",
    "            uuid = hit['entryId']\n",
    "            shortname = hit['projects'][0]['projectShortname']\n",
    "            title = hit['projects'][0]['projectTitle']\n",
    "\n",
    "            print(\"-----------------------\")\n",
    "            print(f\"Title: {title}\")\n",
    "            print(f\"Shortname: {shortname}\")\n",
    "            print(f\"Id: {uuid}\")\n",
    "\n",
    "            project_list.append({'title': title, 'uuid': uuid})\n",
    "\n",
    "        # Handle response pagination if we haven't reached max_projects\n",
    "        url = response_json['pagination']['next']\n",
    "        if url:\n",
    "            params = None\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return project_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### iterate_matrices_tree\n",
    "\n",
    "Recursively traverse a matrix tree and yield the leaf nodes which\n",
    "contain the details for each matrix file (e.g. file name, url, size).\n",
    "\n",
    "The matrix format specification can be found [here](https://github.com/HumanCellAtlas/dcp2/blob/main/docs/dcp2_system_design.rst)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def iterate_matrices_tree(tree, keys=()):\n",
    "    if isinstance(tree, dict):\n",
    "        for k, v in tree.items():\n",
    "            yield from iterate_matrices_tree(v, keys=(*keys, k))\n",
    "    elif isinstance(tree, list):\n",
    "        for file in tree:\n",
    "            yield keys, file\n",
    "    else:\n",
    "        assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "#### download_project_files\n",
    "\n",
    "Fetch a project's metadata, find the file URLs, and download the contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_project_files(catalog: str, project_uuid: str, output_path: str):\n",
    "    # Fetch the project metadata\n",
    "    project_url = f'{PROJECTS_URL}/{project_uuid}'\n",
    "    response = requests.get(project_url, params={'catalog': catalog})\n",
    "    response.raise_for_status()\n",
    "    response_json = response.json()\n",
    "\n",
    "    # Grab the project from the response\n",
    "    project = response_json['projects'][0]\n",
    "\n",
    "    # It is posssible for a matrix file to be included multiple times in the projects response,\n",
    "    # so a list of downloaded URLs is maintained to prevent downloading any file more than once.\n",
    "    file_urls = set()\n",
    "    \n",
    "    # Iterate over the matrices and the contributed analyses to find project files\n",
    "    for key in ('matrices', 'contributedAnalyses'):\n",
    "        tree = project[key]\n",
    "        for path, file_info in iterate_matrices_tree(tree):\n",
    "            url = file_info['url']\n",
    "            if url not in file_urls:\n",
    "                dest_path = os.path.join(output_path, file_info['name'])\n",
    "                download_file(url, dest_path)\n",
    "                file_urls.add(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Access HCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "### Get the latest catalog\n",
    "\n",
    "From the list of catalogs, find the \"latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CATALOG = get_dcp_catalog()\n",
    "print(f\"The DCP catalog is: {CATALOG}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### Fetch project list\n",
    "\n",
    "From the catalog get a short list of projects and print them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_LIST = list_projects(CATALOG, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### Download project files\n",
    "\n",
    "Download the files for the first project in our list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TARGET_PROJECT = PROJECT_LIST[0]\n",
    "\n",
    "print(f\"Downloading files for project '{TARGET_PROJECT['title']}'\")\n",
    "download_project_files(CATALOG, TARGET_PROJECT['uuid'], OUTPUT_DIR)\n",
    "print(\"Downloads Complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "## Provenance\n",
    "\n",
    "Generate information about this notebook environment and the packages installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "Conda and pip installed packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!conda env export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "JupyterLab extensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!jupyter labextension list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "Number of cores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!grep ^processor /proc/cpuinfo | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "Memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!grep \"^MemTotal:\" /proc/meminfo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Copyright 2023 Verily Life Sciences LLC\n",
    "\n",
    "Use of this source code is governed by a BSD-style\n",
    "license that can be found in the LICENSE file or at\n",
    "https://developers.google.com/open-source/licenses/bsd"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "r-cpu.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/r-cpu:m123"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
